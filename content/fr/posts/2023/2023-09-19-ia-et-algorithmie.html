---
title: "IA et algorithmie"
date: "2023-09-19T00:00:00+02:00"
breadcrumbs:
  - title: "Accueil"
    path: "/"
  - title: "Discussions, chantiers en cours"
    path: "/discussions/"
  - title: >-
      IA et algorithmie
url: "/discussions/2023-09-19-ia-et-algorithmie/"
slug: "ia-et-algorithmie"

full_width: false
design:
  full_width: false
  toc:
    present: false
    offcanvas: false


translation_key: communication-website-post-8476456e-6ae2-4508-9cf8-db72e26a5a83

image:
  id: "ecb4ad99-174a-4419-9eb7-8e26e45fae10"
  alt: ""
  credit: >
    <p>Photo by <a href="https://unsplash.com/@markusspiske?utm_source=osuny&amp;utm_medium=referral"> Markus Spiske</a> on <a href="https://unsplash.com/?utm_source=osuny&amp;utm_medium=referral">Unsplash</a></p>

meta_description: >
  
description: >
  

summary: >
  Cette discussion est un chantier en cours. Si elle vous intéresse, n'hésitez pas à venir en discuter!
description_short: >
  Cette discussion est un chantier en cours. Si elle vous intéresse, n'hésitez pas à venir en discuter!

contents_reading_time:
  seconds: 298
  text: >-
    5 minutes
contents:
  - kind: block
    template: chapter
    title: >-
      
    position: 1
    ranks:
      self: false
    data:
      layout: no_background
      text: >-
        <p>J'ai de grandes difficultés avec cela car pour moi une IA, pour mériter ce nom doit être capable d'avoir une résolution non déterminé de l'incohérence, au sens d'Asimov ; l'intelligence commence lorsque le robot résout une incohérence entre son processus cognitif et les 3 règles ou des processus cognitifs distincts. – Le programme et l’algorithme ou plutôt l’algorithmique programmatique sont la mise en œuvre des règles (ou codex d’exécution également connu sous le nom de règles métiers) définies par l’homme.</p><p>Pour comparer avec l'être l'humain, le fait d'être courageux est un marqueur d'intelligence car il s'agit de la résolution du conflit non déterminé (on est pas courageux à chaque fois) entre l'instinct ("cerveau reptilien") et la raison("néo-cortex"). Lorsqu'un programme apprend à reconnaitre un chat, il n'y a pas d'intelligence, de raison ou de choix la dedans. Est-ce bien le cas ? Si l’on songe à l’apprentissage renforcé ou autonome et au sous-jacent qui le permet alors il y a intelligence acquise par la règle, raison par le processus et choix par l’extrant décisionnel issu des 2 notions précédentes transposées dans la logique d’exécution du processus au niveau du code.</p><p>Vous argumentez plus loin qu'on peut différencié la calculette (un outil) de l'IA. Mais en quoi ? Pour moi la seule différence fondamental est la difficulté de comprendre la logique interne.Et c’est précisément la logique interne qui les différencie de part sa complexité.</p><p>A disserter sur le caractère d'outil, de système, d'algorithme ... n'a pas grand chose de technoréaliste. Il s'agit de verbiage pseudo spécialisé.</p><p>Quelqu'un de mon entourage me disait il y a peu : "J'ai rendu ChatGPT triste". Non non et non, chat GPT n'est qu'une calculette à prédire le mot suivant. Pas de choix, pas d'émotion, etc. La plus grosse erreur est selon moi de tomber dans l'anthropomorphisme. </p><p>Exact. Il s’agit d’algorithmiques sophistiquée, le terme intelligent est à rapprocher de son usage pour les smartphones qui ne sont plus de simples téléphones mais des téléphones enrichis et en réalité des ordinateurs embarqués dans des terminaux portables. Smart = connecté et modulaire.</p><p>Pour conclure ce que l'on appel IA n'en est pas une au sens commun et là est la base de l'incompréhension.</p><p>Ce prisme de lecture induit les réponses de nombreuses questions ici posées. Exemple : Algo VS programme = prisme logique VS prisme UI/UX ; les deux sont résumable à de l'opcode, que ce soit fini ou non, que ça puisse sauter en mémoire ou non (cf pointeur) ne sont que des caractéristiques anecdotiques. Certaines affirmations ne sont pas justifiées tel que : Pourquoi un programme/algo devrait être fini (prisme temporel) ? Perso je ne vois pas. Même sous le prisme de l'entropie de l'information, Selon la théorie quantique : l’information est toujours conservée. Ce qui signifie que la décohérence ne s’applique qu’a son organisation et donc pas à son essence.quelle en est la conclusion ? La taille du tuyau limite la taille du flux pouvant passer dedans ? Certes, mais encore ...Si le tuyau est la fibre marine oui. Si le tuyau est le nombre de connexion PoP pour des architectures reposant sur du cloud, leur nombre est dynamique comme je viens de le redécouvrir (exit le cloud souverain à pas cher).</p><p>Ce genre de logique avait un sens lorsque l'on passait un jeu de données dans une moulinette sans en ajouter ou en retirer en cours de route, or on en est plus là.</p><p>tu relances la balle beaucoup plus loin! Je suis probablement d'accord avec toi, et le biais c'est que j'ai résumé des débats sans vraiment maîtriser les sujets. Nous allons améliorer ce texte. J'essaye déjà de fermer une porte que tu ouvres, que l'on puisse avancer : la calculette. Tu comprends bien que je parle ici du nombre d'output lors de l'exécution d'un programme vs une calculatrice : une IA serait alors rien d'autre qu'un immense système de calculatrices (en série et en parallèle), (N’est-ce pas la définition d’un ordinateur quantique au final ? ;-)</p><p>) mais avec aussi beaucoup plus de langage normatif formel abstrait. Également connu sous le nom de langage naturel ? ;-)</p><p>Je ne cherche pas du tout à dire que l'IA serait intelligente, et j'aime beaucoup ta notion de conflit non déterminé. (un bogue?) Pouvons-nous d'abord tomber d'accord sur la calculatrice?</p><p>Le “model” est fondamentalement une calculette (d'un point de vue mathématique), la différence est dans le niveau de donnée. Au lieu de calculer des données, ça calcul le couple de ces données, permettant ainsi de donner une crédence à une valeur morale (et ça, ça dérange !!). Puisqu'on crée le modèle à partir d'une forme de conscience collective plus ou moins filtrée où toute l'attention se porte sur la "qualité" de ces données d’entraînement. Le reste, c'est calculatoire.</p><p>Mais ce modèle à une surcouche, dans celle-ci on trouve le "langage normatif formel".</p><p>"Abstrait" ? C'est une grosse difficulté de cette techno, son "Abstrait" n'est pas le notre puisqu'elle l'a "déduit" par elle-même. L'art de filtrer un modèle reviens à donner des consignes concrètes à propos de choses abstraites. Galère.</p><p>N’est-ce pas plutôt l’intelligence et donc la machine qui galère pour acquérir ce trait de l’intelligence profondément biologique ?</p><p>Le but premier de cette surcouche étant de filtrer les résultats entrée/sortie du modèle, elle peut toutefois grossir qu'à représenter la majorité du programme. Toutefois cette partie c'est concrètement des lignes de code de langage de programmation, donc "auditable" (<i>cf.</i> le commentaire sur l'outil)  C’est vrai pour du stateless mais pas avec une approche contenant une base de données sous la forme de datamart ou de data store (coucou stateful).</p><p>Plus il y a de surcouche par rapport au modèle dans ce que l'on défini être l'IA, plus la question normative se pose. Si l'IA c'est les dernières techno (GAN par filtre, LLM etc) en elle-même, on est très proche de la calculette. Si L'IA c'est ces dernières techno + l'écosystème développé ces dernières années alors à l'inverse le normatif fait loi car le calculatoire est relayé au rang de sous-processus. Il y a donc 2 discussions : l’une à proori essentiellement technique, l’autre qui englobe la technique sans s’y limiter.</p>

      notes: >-
        


      alt: >-
        

      credit: >-
        




---

